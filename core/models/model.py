import logging
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.transforms import Normalize
from core.models.layers import SDPBasedLipschitzConvLayer, SDPBasedLipschitzLinearLayer
from core.models.layers import PoolingLinear, PaddingChannels
from core.models.conv_deq import ConvLipschitzDEQ
from core.models.dense_deq import DenseLipschitzDEQ
from core.splitting import MONPeacemanRachford, MONForwardBackwardSplitting


class NormalizedModel(nn.Module):

  def __init__(self, model, mean, std):
    super(NormalizedModel, self).__init__()
    self.model = model
    self.normalize = Normalize(mean, std)

  def forward(self, x):
    return self.model(self.normalize(x))


class SLLNetwork(nn.Module):

  def __init__(self, config, n_classes):
    super(SLLNetwork, self).__init__()

    conv_depth = config.conv_depth
    num_channels = config.num_channels
    dense_depth = config.dense_depth
    n_features = config.n_features
    conv_size = config.conv_size
    imsize = 32

    self.padding = PaddingChannels(num_channels, 3)

    convs = []
    for _ in range(conv_depth):
      convs.append(SDPBasedLipschitzConvLayer(config, num_channels, conv_size))
    self.convs = nn.Sequential(*convs)
    
    self.avgpool = nn.AvgPool2d(4, divisor_override=4)
    self.flatten = nn.Flatten()

    in_channels = num_channels * 8 * 8
    denses = []
    for _ in range(dense_depth):
      denses.append(SDPBasedLipschitzLinearLayer(config, in_channels, n_features))
    self.denses = nn.Sequential(*denses)

    self.pooling = PoolingLinear(in_channels, n_classes)

  def forward(self, x):
    x = self.padding(x)
    x = self.convs(x)
    x = self.avgpool(x)
    x = self.flatten(x)
    x = self.denses(x)
    return self.pooling(x)



class MONReLU(nn.Module):
  
  def __init__(self, *args):
    super(MONReLU, self).__init__()
    self.relu = nn.ReLU(inplace=False)

  def forward(self, *z):
    return tuple(self.relu(z_) for z_ in z)
  
  def derivative(self, *z):
    return tuple((z_ > 0)*1. for z_ in z)


class MONReLUResidual(nn.Module):
  
  def __init__(self, depth):
    super(MONReLUResidual, self).__init__()
    self.depth = depth+1
    self.relu = nn.ReLU(inplace=False)
    
  def _forward(self, z):
    z = z.split(z.shape[1]//self.depth, dim=1)
    z = [z[0]] + [self.relu(z_) for z_ in z[1:]]
    z = torch.cat(z, dim=1)
    return z
  
  def _derivative(self, z):
    z = z.split(z.shape[1]//self.depth, dim=1)
    z = [torch.ones_like(z[0])] + [(z_ > 0)*1. for z_ in z[1:]]
    z = torch.cat(z, dim=1)
    return z

  def forward(self, *z):
    return tuple(self._forward(z_) for z_ in z)
  
  def derivative(self, *z):
    return tuple(self._derivative(z_) for z_ in z)


class LipschitzNetworkDEQ(nn.Module):

  def __init__(self, config, n_classes):
    super(LipschitzNetworkDEQ, self).__init__()

    conv_depth = config.conv_depth
    num_channels = config.num_channels
    dense_depth = config.dense_depth
    n_features = config.n_features
    conv_size = config.conv_size

    splitting_params = {
      'alpha': config.mon_alpha,
      'tol': config.mon_tol,
      'max_iter': config.mon_max_iter,
      'verbose': False
    }

    x_size = 32 # default
    in_channels = num_channels * 8 * 8 # default

    self.padding = PaddingChannels(num_channels, 3)

    conv = ConvLipschitzDEQ(config, x_size, num_channels, conv_size)
    relu_conv = MONReLUResidual(conv_depth)
    self.mon_conv = MONPeacemanRachford(conv, relu_conv, **splitting_params)

    self.avgpool = nn.AvgPool2d(4, divisor_override=4)
    self.flatten = nn.Flatten()

    dense = DenseLipschitzDEQ(config, in_channels, n_features)
    relu_dense = MONReLUResidual(dense_depth)
    self.mon_dense = MONPeacemanRachford(dense, relu_dense, **splitting_params)

    self.pooling = PoolingLinear(in_channels, n_classes)

  # def get_lipschitz(self):
  #   lip_conv = self.mon_conv.linear_module.lip
  #   lip_dense = self.mon_dense.linear_module.lip
  #   return lip_conv, lip_dense

  def forward(self, x):
    x = self.padding(x)
    x = self.mon_conv(x)[-1]
    x = self.mon_conv.linear_module.forward_g(x)
    x = self.avgpool(x)
    x = self.flatten(x)
    x = self.mon_dense(x)[-1]
    x = self.mon_dense.linear_module.forward_g(x)
    return self.pooling(x)



